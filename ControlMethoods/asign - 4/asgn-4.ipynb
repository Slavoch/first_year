{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af5dede",
   "metadata": {},
   "source": [
    "## Advanced Control Methods | Assignment 4\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The last assignment is devoted to the application of the methods of classical Computer Vision to the problem of calculating the number of fingers that are shown to the camera. Check the file *fingers.mov* that we will be working with.\n",
    "\n",
    "It is beyond necessity to prove the importance of the Computer Vision in robotics. Let us just briefly highlight the following.\n",
    "\n",
    "- CV in application to the autonomous robotocs is a part of control in a broad sense of the word. Its role is to transform millions of numbers in few ones as fast as possible.\n",
    "\n",
    "- Classical (without NNs) CV is a set of approaches that rely on the handcrafted features. From a computational point of view these methods are often faster, while being worse in terms of performance, which was the whole point of the NNs develpment. Another factor is that many classical algorithms are supported by very low-powered computers, SOCs, and microcontrollers, and NNs are not.\n",
    "\n",
    "- All the methods are supposed to be used in this assignment could be applied to another CV problems. Mask processing and analysis is one of the foundations of the rapid and effective prototyping of the vision pipelines.\n",
    "\n",
    "In the first section the structure for the code is introduced. Since we do not use any learning-based or autoadjustment techniques here, it will be necessary to tune the color filter to detect the hand, which is in the second section of the notebook. In the third section of the notebook you are supposed to write the code that will calculate the number of the fingers in the frame.\n",
    "\n",
    "### Methods\n",
    "\n",
    "Here we provide a short list of sketches of approaches to calculate fingers in the frame, feel free to use any of them. Do not limit yourself by those methods, everything (except for NNs) will be accepted as long as it works. Of course, you could try them for fun, and probably you will get a solution that works better than the author's :)\n",
    "\n",
    "**Sketetonization**\n",
    "\n",
    "- mask obtainment\n",
    "- mask refinement: denoising, smoothing. Leaving a single connected component\n",
    "- skeletonization\n",
    "- fingertip obtainment (via filter2d)\n",
    "- fingertip filtering\n",
    "\n",
    "**Convexity defects**\n",
    "\n",
    "- mask obtainment\n",
    "- mask refinement: denoising, smoothing. Leaving a single connected component\n",
    "- finding contour, finding rough approximation\n",
    "- finding convexity defects, processing them\n",
    "\n",
    "**Morphology**\n",
    "\n",
    "- mask obtainment\n",
    "- mask refinement: denoising, smoothing. Leaving a single connected component\n",
    "- top hat/black hat morphological operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d05ffb1",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2 style=\"color:#A7BD3F;\">Section 1: Preparations</h2>\n",
    "\n",
    "Please examine the code below. Essentially it is a wrapper around a frame processing.\n",
    "\n",
    "Use 'q' to stop the execution. Due to the implementation details this feature works with english language only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e80f4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class FrameProcessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def processing_loop(self, source, lth, hth, max_frame_num = -1,\\\n",
    "                        alternative_source=\"\", save_to_file=\"\"):\n",
    "        i = 0\n",
    "        results = []\n",
    "\n",
    "        output_file = None\n",
    "        \n",
    "        #out = cv2.VideoWriter('outpy.avi', cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "#                               30, (WINDX, WINDY))\n",
    "#         out.write(canvas)\n",
    "#         out.release()\n",
    "        \n",
    "        while (True):\n",
    "            retval, frame = source.read()\n",
    "\n",
    "            if (retval == False):\n",
    "                print(\"Cannot read frame\")\n",
    "                \n",
    "                if (alternative_source != \"\"):\n",
    "                    print(\"Opening alternative source \", alternative_source)\n",
    "                    source = cv2.VideoCapture(alternative_source)\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    print(\"Exiting loop\")\n",
    "                    break\n",
    "\n",
    "            result = self.process_frame(frame, lth, hth)\n",
    "            \n",
    "            results.append(result)\n",
    "\n",
    "            key = cv2.waitKey(100) & 0xFF\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            if (key == ord('q')):\n",
    "                break\n",
    "                        \n",
    "            if (max_frame_num != -1 and i >= max_frame_num):\n",
    "                break\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def process_frame(self, frame, lth, hth):\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db713c09",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2 style=\"color:#A7BD3F;\">Section 2: Color filter tuning</h2>\n",
    "\n",
    "Tune the parameters of the color filtering. Note that it is performed in *HSV* color space. After you did that, write these parameters into *lth* and *hth* respectively. These parameters will be used further in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58488c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# YOUR DEFAULT PARAMETERS BELOW\n",
    "#############################################\n",
    "\n",
    "lth, hth = (0, 0, 0), (255, 255, 255)\n",
    "\n",
    "#############################################\n",
    "# YOUR DEFAULT PARAMETERS ABOVE\n",
    "#############################################\n",
    "\n",
    "class ColorFilterTuning(FrameProcessor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        cv2.namedWindow(\"color_filter_parameters\")\n",
    "                \n",
    "        cv2.createTrackbar('rl', 'color_filter_parameters', lth[0], 255, self.nothing)\n",
    "        cv2.createTrackbar('gl', 'color_filter_parameters', lth[1], 255, self.nothing)\n",
    "        cv2.createTrackbar('bl', 'color_filter_parameters', lth[2], 255, self.nothing)\n",
    "        cv2.createTrackbar('rh', 'color_filter_parameters', hth[0], 255, self.nothing)\n",
    "        cv2.createTrackbar('gh', 'color_filter_parameters', hth[1], 255, self.nothing)\n",
    "        cv2.createTrackbar('bh', 'color_filter_parameters', hth[2], 255, self.nothing)\n",
    "\n",
    "    def nothing(self, inp):\n",
    "        pass\n",
    "    \n",
    "    def process_frame(self, frame, lth, hth):\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        low_th =  (cv2.getTrackbarPos('rl', 'color_filter_parameters'),\n",
    "                   cv2.getTrackbarPos('gl', 'color_filter_parameters'),\n",
    "                   cv2.getTrackbarPos('bl', 'color_filter_parameters'))\n",
    "        \n",
    "        high_th = (cv2.getTrackbarPos('rh', 'color_filter_parameters'),\n",
    "                   cv2.getTrackbarPos('gh', 'color_filter_parameters'),\n",
    "                   cv2.getTrackbarPos('bh', 'color_filter_parameters'))\n",
    "        \n",
    "        mask = cv2.inRange(frame, low_th, high_th)\n",
    "        \n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.imshow(\"mask\", mask)\n",
    "        \n",
    "        return (low_th, high_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b28d8b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2626571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color filter parameters:  (0, 0, 0) (255, 255, 255)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "video_file = \"fingers.mov\"\n",
    "\n",
    "cam = cv2.VideoCapture(video_file)\n",
    "\n",
    "#print(cam)\n",
    "# frame_offset = 100\n",
    "# cam.set(1, frame_offset)\n",
    "\n",
    "tuner = ColorFilterTuning()\n",
    "\n",
    "colors = tuner.processing_loop(cam, None, None, max_frame_num = -1,\\\n",
    "            alternative_source=video_file)\n",
    "lth, hth = colors[-1]\n",
    "\n",
    "print(\"Color filter parameters: \", lth, hth)\n",
    "cam.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56580828",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2 style=\"color:#A7BD3F;\">Section 3: Fingers counting</h2>\n",
    "\n",
    "Implement the core finger counting algorithm in a frame given below. Don't forget to use *lth* and *hth* parameters that stand for the triplets of lower and higher color bounds respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b99342f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingersCounter(FrameProcessor):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cv2.namedWindow('bar')\n",
    "        cv2.createTrackbar('val1','bar',0,255,self.change_val)\n",
    "        cv2.createTrackbar('val2','bar',0,255,self.change_val)\n",
    "        cv2.createTrackbar('val3','bar',0,255,self.change_val)\n",
    "\n",
    "\n",
    "        cv2.createTrackbar('val1h','bar',0,255,self.change_val)\n",
    "        cv2.createTrackbar('val2h','bar',0,255,self.change_val)\n",
    "        cv2.createTrackbar('val3h','bar',0,255,self.change_val)\n",
    "\n",
    "        cv2.setTrackbarPos(\"val1\",'bar',0)\n",
    "        cv2.setTrackbarPos(\"val2\",'bar',0)\n",
    "        cv2.setTrackbarPos(\"val3\",'bar',118)\n",
    "\n",
    "        cv2.setTrackbarPos(\"val1h\",'bar',255)\n",
    "        cv2.setTrackbarPos(\"val2h\",'bar',255)\n",
    "        cv2.setTrackbarPos(\"val3h\",'bar',255)\n",
    "    \n",
    "    def change_val(self,inp):\n",
    "        pass\n",
    "    \n",
    "    def filter_cc(self, mask, area_th = -1):\n",
    "        connectivity = 4\n",
    "        output = cv2.connectedComponentsWithStats(mask, connectivity, cv2.CV_32S)\n",
    "        num_labels = output[0]\n",
    "        labels = output[1]\n",
    "        stats = output[2]\n",
    "        #centroids = output[3]\n",
    "\n",
    "        if (num_labels < 1):\n",
    "            return mask\n",
    "        \n",
    "        if (area_th == -1):\n",
    "            max_area = 1\n",
    "            max_label = 1\n",
    "            \n",
    "            for i in range(1, num_labels):\n",
    "                area = stats[i, cv2.CC_STAT_AREA]\n",
    "                \n",
    "                if (area > max_area):\n",
    "                    max_area = area\n",
    "                    max_label = i\n",
    "            \n",
    "            for i in range(1, len(stats)):\n",
    "                if (i != max_label):\n",
    "                    mask[np.where(labels == i)] = 0\n",
    "                    \n",
    "        else:\n",
    "            for i in range(len(stats)):\n",
    "                area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "                if (area < area_th):\n",
    "                    mask[np.where(labels == i)] = 0\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def fill_holes (self, img):\n",
    "        (h, w) = img.shape\n",
    "\n",
    "        before_area = img.sum ()\n",
    "\n",
    "        img_enlarged = np.zeros ((h + 2, w + 2), np.uint8)\n",
    "        img_enlarged [1:h+1, 1:w+1] = img\n",
    "\n",
    "        img_enl_not = cv2.bitwise_not (img_enlarged)\n",
    "        th, im_th = cv2.threshold (img_enl_not, 220, 255, cv2.THRESH_BINARY_INV);\n",
    "\n",
    "        im_floodfill = im_th.copy()\n",
    "\n",
    "        h, w = im_th.shape[:2]\n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "        cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    "        im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "        im_out = im_th | im_floodfill_inv\n",
    "\n",
    "        result = im_out [1:h-1, 1:w-1]\n",
    "\n",
    "        #after_area = result.sum ()\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def process_frame(self, frameOld, lth, hth):\n",
    "        #cv2.imshow(\"frame\", frame)\n",
    "        xx, yy = 400,200\n",
    "        wx ,hy = 700,380\n",
    "        frame = frameOld[yy:yy +hy,xx:xx+wx]\n",
    "\n",
    "        low_th = (cv2.getTrackbarPos(\"val1\",'bar'),cv2.getTrackbarPos(\"val2\",'bar'),cv2.getTrackbarPos(\"val3\",'bar'))\n",
    "        high_th = (cv2.getTrackbarPos(\"val1h\",'bar'),cv2.getTrackbarPos(\"val2h\",'bar'),cv2.getTrackbarPos(\"val3h\",'bar'))\n",
    "        mask = cv2.inRange(frame,low_th, high_th)\n",
    "        hsv_image = cv2.cvtColor(frame,cv2.COLOR_RGB2HSV)\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        eroded = cv2.dilate(mask,kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(eroded,\n",
    "                                                   cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        mask = np.zeros(frame.shape, np.uint8)\n",
    "        mask2 = np.zeros(frame.shape, np.uint8)\n",
    "\n",
    "        wrist_area = 0\n",
    "        # считаем аппроксимацию кисти + обьем кисти + то что будем отображать\n",
    "        for cnt in contours:\n",
    "            length = cv2.arcLength(cnt,True)\n",
    "\n",
    "            epsilon = 0.007*length\n",
    "            approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "\n",
    "            if length > 100:\n",
    "                hull = cv2.convexHull(approx)\n",
    "                cv2.drawContours(frame, [cnt], -1, (0,255,0),2)\n",
    "                cv2.drawContours(frame, [hull], -1, (0,0,255),2)\n",
    "                cv2.fillPoly(mask,[approx],color = (255,255,255))\n",
    "                cv2.fillPoly(mask2,[hull],color = (255,0,0))\n",
    "                if(cv2.contourArea(cnt) > wrist_area):\n",
    "                    wrist_area = cv2.contourArea(cnt)\n",
    "        # просто для красоты \n",
    "        visual = cv2.add(mask,mask2)\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        cv2.imshow(\"eroded\",eroded)\n",
    "        cv2.imshow(\"visual\",visual)\n",
    "\n",
    "        #переводим в чернобелый все\n",
    "        grayImage = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        tresh, mask_wb = cv2.threshold(grayImage, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        grayImage = cv2.cvtColor(mask2, cv2.COLOR_BGR2GRAY)\n",
    "        tresh, mask2_wb = cv2.threshold(grayImage, 20, 255, cv2.THRESH_BINARY)\n",
    "        # вычитаем всю оббласть и кисть\n",
    "        bin_xor =cv2.bitwise_xor(mask_wb,mask2_wb)\n",
    "\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(bin_xor,\n",
    "                                                   cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        #считаем области между пальцами \n",
    "        count = 0\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if(area / wrist_area > 1/43): # подобрано \n",
    "                count+=1\n",
    "\n",
    "        #считаем пальцы\n",
    "        count = max(count - 1,0)\n",
    "        #вывод\n",
    "        cv2.putText(bin_xor,str(count), (40,40), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)\n",
    "        cv2.imshow(\"bin_xor\",bin_xor)\n",
    "\n",
    "        return count\n",
    "    #def process_frame(self, frame, lth, hth):\n",
    "        #############################################\n",
    "        # YOUR CODE BELOW\n",
    "        #############################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        #############################################\n",
    "        # YOUR CODE ABOVE\n",
    "        #############################################\n",
    "        \n",
    "    #    cv2.imshow(\"stages\", stages_concat)\n",
    "        \n",
    "    #    return fingers_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e42c068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read frame\n",
      "Exiting loop\n",
      "[4, 5, 1, 1, 1, 4, 5, 5, 1, 1, 1, 5, 5, 5, 5, 4, 0, 0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(\"fingers.mov\")\n",
    "\n",
    "\n",
    "finger_counter = FingersCounter()\n",
    "\n",
    "fingers_num = finger_counter.processing_loop(cam, lth, hth)\n",
    "\n",
    "print(fingers_num)\n",
    "\n",
    "cam.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30ee1f",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2 style=\"color:#A7BD3F;\">Section 4: Grading</h2>\n",
    "\n",
    "The grading scheme is quite straightforward: *0.5* or more finger  gives full grade of *100* points with linear interpolation downwards.\n",
    "\n",
    "Please execute the cell below to grade your solution. As you can see, it runs your counting function on a pre-recorded video and compares the results with the markup. In order to avoid confusion, only the unambiguous cases are counted in the grading.\n",
    "\n",
    "In case of any questions, reach out to Ilya Osokin (@elijahmipt) or Georgy Malaniya (@OdinManiac) on Telegram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35ef2340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your grade is  \u001b[92m91 out of 100; 44 frames out of 96\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reference_fingers_num = [5, 5, 1, 0, 0, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 4, 3, 3,\\\n",
    "                         3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2,\\\n",
    "                         2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,\\\n",
    "                         2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\n",
    "                         2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1,\\\n",
    "                         3, 4, 0, 0, 0, 1]\n",
    "\n",
    "max_grade = 100\n",
    "\n",
    "corr_num = 0\n",
    "\n",
    "for r, s in zip(reference_fingers_num, fingers_num):\n",
    "    if (r == s):\n",
    "        corr_num += 1\n",
    "\n",
    "acc = corr_num / len(reference_fingers_num)\n",
    "\n",
    "#print(\"correct \", corr_num, \" out of \", len(reference_fingers_num),\n",
    "#      corr_num / len(reference_fingers_num))\n",
    "\n",
    "grade = min(acc * 2, 1) * max_grade\n",
    "\n",
    "print(\"Your grade is \", \"\\033[92m{}\\033[0m\".format(str(int(grade)) +\\\n",
    "        \" out of \" + str(max_grade) + \"; \" + str(corr_num) + \" frames out of \"\n",
    "        + str(len(reference_fingers_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439df30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a2279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5632ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8527a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
